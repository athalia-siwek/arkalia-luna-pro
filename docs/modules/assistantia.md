# ğŸ§  AssistantIA â€” Module Cognitif IntÃ©grÃ©

![Version](https://img.shields.io/badge/version-v2.4.0-blue)
![CI](https://github.com/athalia-siwek/arkalia-luna-pro/actions/workflows/ci.yml/badge.svg)
![License](https://img.shields.io/badge/license-Proprietary-red)
![Coverage](https://img.shields.io/badge/coverage-93%25-brightgreen)

Le module `assistantia/` est lâ€™interface dâ€™assistance IA locale dâ€™Arkalia-LUNA. Il agit comme **guide conversationnel**, interface cognitive et **rÃ©pondant intelligent** aux requÃªtes utilisateurs.

---

## ğŸ§  RÃ´le du module

- Dialogue IA avec lâ€™utilisateur
- RÃ©ponses contextuelles personnalisÃ©es
- Interface Ã©volutive vers lâ€™IA autonome embarquÃ©e
- Support aux modules (Helloria, Reflexiaâ€¦)

---

## ğŸš€ Lancement manuel

```bash
uvicorn modules.assistantia.core:app --port 8001
```

ğŸ“ **Port configurable** dans `docker-compose.yml` ou `config/`.

---

## ğŸ”„ Endpoints disponibles

| MÃ©thode | URL    | Description                      |
|---------|--------|----------------------------------|
| POST    | /chat  | Envoie un message Ã  lâ€™IA locale  |
| GET     | /status| Ã‰tat du module assistantia       |

---

## ğŸ§ª Tests associÃ©s

- **Fichiers** :
  - `test_assistantia.py` (unitaires)
  - `test_assistantia_integration.py` (intÃ©gration)

âœ… **Couverture** : 81 % â€” avec plan dâ€™extension vers les cas dâ€™erreur et logs dÃ©taillÃ©s.

---

## ğŸŒ ConnectivitÃ© modulaire

Le module est connectÃ© Ã  :
- `helloria/` (API externe)
- `reflexia/` (logs et surveillance IA)
- `nyxalia/` (interprÃ©tation mobile)

ğŸ’¡ **PrÃªt pour une extension** vers Ollama, Langchain, ou des modÃ¨les hybrides.

---

ğŸ¯ **Objectif futur** : une IA embarquÃ©e rÃ©flexive, contextuelle, auto-ajustable.

---

## ğŸ§  AssistantIA â€” Utilisation et IntÃ©gration LLM

L'AssistantIA est conÃ§u pour offrir une interaction fluide et intelligente avec les utilisateurs, en intÃ©grant des modÃ¨les de langage de pointe (LLM) pour comprendre et rÃ©pondre aux requÃªtes de maniÃ¨re contextuelle.

---

## ğŸš€ FonctionnalitÃ©s Principales

- **RÃ©ponses Contextuelles** : GrÃ¢ce Ã  l'intÃ©gration de modÃ¨les LLM comme Mistral et Llama2, l'AssistantIA peut fournir des rÃ©ponses prÃ©cises et adaptÃ©es au contexte de la conversation.
- **Personnalisation** : L'AssistantIA s'adapte aux prÃ©fÃ©rences de l'utilisateur, offrant une expÃ©rience personnalisÃ©e.
- **IntÃ©gration Facile** : Peut Ãªtre intÃ©grÃ© dans diverses applications via des API REST, facilitant l'interaction avec d'autres systÃ¨mes.

---

## ğŸŒ Exemple d'Utilisation

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Quelle est la philosophie d'Arkalia ?"}'
```

---

## ğŸ§  ModÃ¨les LLM IntÃ©grÃ©s

L'AssistantIA utilise des modÃ¨les LLM locaux pour garantir la confidentialitÃ© et l'efficacitÃ©. Les modÃ¨les sont stockÃ©s localement et peuvent Ãªtre mis Ã  jour ou remplacÃ©s selon les besoins.

---

## ğŸ“Š Structure JSON Entrante/Sortante

### RequÃªte

```json
{
  "message": "Bonjour Arkalia",
  "mode": "empathique",
  "lang": "fr",
  "user_id": "12345"
}
```

### RÃ©ponse

```json
{
  "rÃ©ponse": "Bonjour ! Je suis AssistantIA, prÃªt Ã  vous aider."
}
```

---

## âš™ï¸ ParamÃ¨tres Optionnels

- **mode** : DÃ©finit le mode de raisonnement de l'IA (ex: neutre, empathique).
- **lang** : Langue de rÃ©ponse attendue (ex: fr, en).
- **user_id** : Identifiant utilisateur pour personnalisation.

---

## ğŸ“Š SchÃ©ma d'Interaction

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant A as AssistantIA
    participant O as Ollama
    U->>A: POST /chat (message)
    A->>O: Query modÃ¨le
    O-->>A: RÃ©ponse IA
    A-->>U: JSON { "rÃ©ponse": "..." }
```

---

ğŸ§  *L'AssistantIA est votre partenaire intelligent pour une interaction IA enrichissante et sÃ©curisÃ©e.*

Pour des considÃ©rations de sÃ©curitÃ©, veuillez consulter [la section SÃ©curitÃ©](../security/security.md).

---

Â© 2025 **Athalia** â€“ Tous droits rÃ©servÃ©s.
ğŸ¤– Powered by Arkalia ReflexIA `v1.x`
