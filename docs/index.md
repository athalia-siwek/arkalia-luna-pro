# ğŸ“š Documentation Arkalia-LUNA

Bienvenue dans la documentation technique dâ€™**Arkalia-LUNA**, un systÃ¨me cognitif IA local, **modulaire**, **auto-rÃ©flexif** et **entiÃ¨rement documentÃ©**.

Cette documentation couvre lâ€™ensemble des composants : modules actifs, API locale, scripts dâ€™orchestration, tests, automatisation et intÃ©gration de modÃ¨les IA (LLM).

---

## ğŸ§  Modules actifs

- `reflexia` â€” RÃ©flexion adaptative et surveillance systÃ¨me  
- `zeroia` â€” Raisonnement logique et dÃ©cisions contextuelles  
- `nyxalia` â€” Interfaces mobiles et externes  
- `helloria` â€” Passerelle FastAPI et serveur local  

---

## âš™ï¸ FonctionnalitÃ©s couvertes dans la documentation

- ğŸ§  **Modules IA actifs**
- âš™ï¸ **API FastAPI** (avec endpoints `/status`, `/module/trigger`, etc.)
- ğŸ§¬ **Structure du noyau** (kernel & devstation)
- ğŸ” **Scripts & automatisation** (`ark-test`, `ark-docker-rebuild.sh`, etc.)
- ğŸ§ª **Tests unitaires & CI/CD** (pytest, ruff, GitHub Actions)
- ğŸ³ **Docker & dÃ©ploiement local**

---

## ğŸ” Configuration locale des modÃ¨les (Ollama)

> Utilisation des modÃ¨les LLM **localement avec `ollama`**, sans consommer lâ€™espace disque interne du Mac.

â¡ Voir le dÃ©pÃ´t dÃ©diÃ© : [arkalia-ollama (GitHub)](https://github.com/athalia-siwek/arkalia-ollama)

### âœ… ModÃ¨les installÃ©s :
- `mistral`
- `tinyllama`
- `llama2`

ğŸ“ **Chemin de stockage** :  
`/Volumes/T7/devstation/ollama_data/models`

---

ğŸ§­ *Cette documentation Ã©volue en parallÃ¨le du systÃ¨me IA. Toute mise Ã  jour majeure de code est automatiquement synchronisÃ©e avec cette page via GitHub Actions (MkDocs).*  