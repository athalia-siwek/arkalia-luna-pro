# ğŸš€ API FastAPI â€” Arkalia-LUNA

L'API FastAPI permet Ã  des agents externes, humains ou systÃ¨mes, de communiquer avec Arkalia-LUNA de maniÃ¨re **locale, modulaire et sÃ©curisÃ©e**.

---

## ğŸŒ Endpoint principal

- **URL locale** : `http://127.0.0.1:8000/`
- **Serveur** : `Uvicorn` (via Docker ou en local)
- **Point d'entrÃ©e** : `helloria.core:app`

### â–¶ï¸ Commande de dÃ©marrage manuelle

```bash
uvicorn helloria.core:app --reload

ğŸ’¡ Alternativement, utiliser docker-compose up ou le script ark-docker.

MÃ©thode
URL
Description
GET
/
Test de vie : "Bienvenue dans Helloria"
POST
/chat
Envoie un prompt Ã  l'IA locale (assistantia)
GET
/status
Retourne l'Ã©tat gÃ©nÃ©ral du systÃ¨me
GET
/echo?msg=x
RÃ©pond avec le message donnÃ©


â¸»

ğŸ” SÃ©curitÃ© & accÃ¨s
	â€¢	API uniquement exposÃ©e en local
	â€¢	PossibilitÃ© future d'ajouter :
	â€¢	Authentification par clÃ©
	â€¢	Rate limiting
	â€¢	Journalisation des accÃ¨s via reflexia

â¸»

ğŸ“¦ Design modulaire

Chaque endpoint est dÃ©lÃ©guÃ© Ã  un module :
	â€¢	helloria/ = orchestration API
	â€¢	assistantia/ = gÃ©nÃ©ration IA
	â€¢	reflexia/ = mÃ©triques & diagnostics
	â€¢	nyxalia/ = interprÃ©tation mobile

â¸»

âœ… Architecture pensÃ©e pour l'extensibilitÃ© et le contrÃ´le par module.

# ğŸ“Œ Arkalia-LUNA Documentation Technique

## Version Actuelle

**v2.0.2 â€” 20 juin 2025**
ğŸ”„ Git tag synchronisÃ©, CI/CD active, Docker stable, tests validÃ©s Ã  100 %

## ğŸ§  Modules IA Actifs

| Module      | RÃ´le                                | Ã‰tat       |
|-------------|-------------------------------------|------------|
| assistantia | IA contextuelle via /chat + Ollama  | âœ… Stable  |
| helloria    | Serveur d'entrÃ©e FastAPI            | âœ… Stable  |
| reflexia    | Superviseur cognitif & metrics      | âœ… Stable  |
| nyxalia     | Interface cognitive mobile          | âœ… Stable  |

## ğŸš€ API Active

**POST /chat â€” AssistantIA**

Utilisation : envoie un message Ã  l'IA locale (Ollama mistral)

**RequÃªte :**

```json
{
  "message": "Bonjour Arkalia"
}
```

**RÃ©ponse :**

```json
{
  "rÃ©ponse": "Bonjour ! Je suis AssistantIA, prÃªt Ã  vous aider."
}
```

**Erreurs gÃ©rÃ©es :**

| Cas               | Statut | Message retournÃ©            |
|-------------------|--------|-----------------------------|
| Body vide         | 422    | Champ message requis        |
| Prompt vide       | 200    | [âš ï¸ RÃ©ponse IA vide]        |
| ModÃ¨le non supportÃ© | 500  | ValueError levÃ©e            |
| Timeout Ollama    | 500    | [Erreur IA] ReadTimeout     |

## ğŸ§ª Tests & Couverture

- âœ… 35/35 tests passÃ©s
- âœ… Couverture : 92 %
- âœ… Modules testÃ©s : assistantia, ollama_connector, helloria, reflexia, nyxalia, hooks, scripts

## ğŸ³ Environnement Docker

- Conteneur stable (ark-docker)
- Ollama local requis (mistral, tinyllama)
- FastAPI exposÃ© sur localhost:8000

## ğŸ“˜ Site public MkDocs

Disponible ici : arkalia-luna-pro GitHub Pages
Sitemap automatique, Mermaid, thÃ¨me personnalisÃ© Bleu Coton Nuit, badge coverage 92 %.

---

## ğŸ§­ Prochaine Ã©tape : Arkalia LUNA Nexus â€” interface IA guidÃ©e, cognitive, et adaptative.

## ğŸ“Š Flux de Communication â€” /chat

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant A as AssistantIA
    participant O as Ollama (modÃ¨le local)
    U->>A: POST /chat (message)
    A->>O: Query modÃ¨le (via `query_ollama`)
    O-->>A: RÃ©ponse IA (texte brut)
    A-->>U: JSON { "response": "..." }
```

## ğŸ“š Cas d'Usage

### Poser une Question
Envoyez une requÃªte POST Ã  `/chat` avec votre question pour obtenir une rÃ©ponse contextuelle de l'IA.

### Mode Debug
Utilisez le paramÃ¨tre `debug=true` pour obtenir des informations dÃ©taillÃ©es sur le traitement de la requÃªte.

## âš ï¸ Erreurs Typiques

| Erreur               | Cause Possible                  | Correction SuggestÃ©e            |
|----------------------|---------------------------------|---------------------------------|
| Body vide            | RequÃªte sans champ `message`    | Ajouter un champ `message`      |
| Prompt vide          | Champ `message` vide            | Fournir un texte dans `message` |
| ModÃ¨le non supportÃ©  | ModÃ¨le IA non disponible        | VÃ©rifier la configuration du modÃ¨le |
| Timeout Ollama       | Temps d'attente dÃ©passÃ©         | VÃ©rifier la connexion et les ressources |

Pour plus de dÃ©tails sur l'AssistantIA, consultez [AssistantIA](assistantia.md).

### POST /chat

- **Body :** `{ "message": str }`
- **RÃ©ponses :**
  - `200` â†’ `{ "rÃ©ponse": str }`
  - `400` â†’ `{ "detail": "Message vide." }`
  - `422` â†’ validation automatique si champ manquant

## ğŸ§  Module `reflexia` â€” Analyse cognitive rÃ©flexive

Reflexia est le module d'observation et d'auto-analyse du systÃ¨me Arkalia.
Il lit des mÃ©triques internes (CPU, mÃ©moire, etc.), Ã©value leur criticitÃ©, et peut sauvegarder un Ã©tat rÃ©flexif.

### ğŸ”¹ Fonctions exposÃ©es :

| Fonction | Description |
|---------|-------------|
| `launch_reflexia_check()` | Lance un scan rÃ©flexif et retourne un dictionnaire contenant le statut du systÃ¨me. |

### ğŸ”¬ Exemple de retour :

```json
{
  "status": "normal"
}

Dossiers :
  â€¢  reflexia/core.py : fonction principale
  â€¢  reflexia/logic/*.py : analyse CPU, snapshot JSON, dÃ©cisions
  â€¢  reflexia/tests/unit/ : 5 fichiers de test, tous validÃ©s
```

### ğŸ§  ReflexIA â€” VÃ©rification rÃ©flexive instantanÃ©e

- ğŸ” Description : Analyse rÃ©flexive instantanÃ©e â€” rÃ©cupÃ¨re les mÃ©triques systÃ¨me, les Ã©value, et retourne un diagnostic.
- ğŸ“‚ Module : modules/reflexia/
- âš™ï¸ Fonction appelÃ©e : launch_reflexia_check()

ğŸ”„ Exemple de rÃ©ponse :
```json
{
  "status": "ok",
  "metrics": {
    "cpu": 72.5,
    "ram": 61.8,
    "latency": 145
  }
}
```

```bash
curl http://localhost:8000/reflexia/check | jq
