#!/usr/bin/env python3
# üöÄ scripts/ark-performance-benchmark.py
# Script d'ex√©cution des benchmarks performance Arkalia-LUNA

"""
Script de benchmarking performance pour Arkalia-LUNA Enhanced v2.7.1

Fonctionnalit√©s :
- Lance tous les tests de performance
- Collecte et sauvegarde les m√©triques
- G√©n√®re rapport HTML
- D√©tecte r√©gressions performance
"""

from core.ark_logger import ark_logger
import argparse
import json
import os
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path

# Ajouter le chemin des modules
sys.path.insert(0, str(Path(__file__).parent.parent))


def run_performance_tests(output_dir="benchmark_results"):
    """Lance les tests de performance et collecte les r√©sultats"""

    ark_logger.info("üöÄ Lancement des benchmarks performance Arkalia-LUNA", extra={"module": "scripts"})
    ark_logger.info("=" * 60, extra={"module": "scripts"})

    # Cr√©er dossier de r√©sultats
    results_dir = Path(output_dir)
    results_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Configuration environnement pour les tests
    env = os.environ.copy()
    env.update(
        {
            "ZEROIA_DECISION_THRESHOLD": "2.0",
            "CIRCUIT_LATENCY_THRESHOLD_MS": "10.0",
            "EVENT_STORE_WRITE_THRESHOLD_MS": "50.0",
            "PYTEST_CURRENT_TEST": "performance",
        }
    )

    # Commande pytest pour les tests de performance
    cmd = [
        "python",
        "-m",
        "pytest",
        "tests/performance/",
        "-v",
        "--tb=short",
        "-m",
        "performance",
        "--capture=no",  # Afficher les prints
    ]

    ark_logger.info(f"üìä Commande : {' '.join(cmd, extra={"module": "scripts"})}")
    ark_logger.info(f"üìÅ R√©sultats dans : {results_dir}", extra={"module": "scripts"})
    ark_logger.info("")

    # Ex√©cuter les tests
    start_time = time.time()

    try:
        result = subprocess.run(
            cmd,
            env=env,
            capture_output=True,
            text=True,
            timeout=300,  # 5 minutes max
        )

        end_time = time.time()
        duration = end_time - start_time

        # Sauvegarder les r√©sultats
        results = {
            "timestamp": timestamp,
            "duration_seconds": duration,
            "return_code": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "environment": {
                "python_version": sys.version,
                "os": os.name,
                "platform": sys.platform,
            },
        }

        results_file = results_dir / f"benchmark_results_{timestamp}.json"
        with open(results_file, "w") as f:
            json.dump(results, f, indent=2)

        # Afficher r√©sultats
        ark_logger.info(f"‚úÖ Benchmarks termin√©s en {duration:.1f}s", extra={"module": "scripts"})
        ark_logger.info(f"üìä Code retour : {result.returncode}", extra={"module": "scripts"})
        ark_logger.info(f"üíæ R√©sultats sauv√©s : {results_file}", extra={"module": "scripts"})

        if result.returncode == 0:
            ark_logger.info("üéØ Tous les benchmarks ont r√©ussi !", extra={"module": "scripts"})
        else:
            ark_logger.info("‚ö†Ô∏è Certains benchmarks ont √©chou√©", extra={"module": "scripts"})

        # Afficher stdout si pr√©sent
        if result.stdout:
            ark_logger.info("\nüìã Sortie des tests :", extra={"module": "scripts"})
            ark_logger.info("-" * 40, extra={"module": "scripts"})
            ark_logger.info(result.stdout, extra={"module": "scripts"})

        if result.stderr:
            ark_logger.info("\n‚ùå Erreurs :", extra={"module": "scripts"})
            ark_logger.info("-" * 40, extra={"module": "scripts"})
            ark_logger.info(result.stderr, extra={"module": "scripts"})

        return result.returncode == 0

    except subprocess.TimeoutExpired:
        ark_logger.info("‚ùå Timeout : Les benchmarks ont pris trop de temps (>5min)", extra={"module": "scripts"})
        return False

    except Exception as e:
        ark_logger.info(f"‚ùå Erreur lors de l'ex√©cution : {e}", extra={"module": "scripts"})
        return False


def generate_summary_report(output_dir="benchmark_results"):
    """G√©n√®re un rapport de synth√®se des benchmarks"""

    results_dir = Path(output_dir)
    if not results_dir.exists():
        ark_logger.info(f"‚ùå Dossier {output_dir} introuvable", extra={"module": "scripts"})
        return

    # Trouver le fichier de r√©sultats le plus r√©cent
    json_files = list(results_dir.glob("benchmark_results_*.json"))
    if not json_files:
        ark_logger.info("‚ùå Aucun fichier de r√©sultats trouv√©", extra={"module": "scripts"})
        return

    latest_file = max(json_files, key=lambda f: f.stat().st_mtime)

    try:
        with open(latest_file) as f:
            results = json.load(f)

        ark_logger.info("\nüìä RAPPORT DE SYNTH√àSE BENCHMARKS", extra={"module": "scripts"})
        ark_logger.info("=" * 50, extra={"module": "scripts"})
        ark_logger.info(f"üìÖ Date : {results['timestamp']}", extra={"module": "scripts"})
        ark_logger.info(f"‚è±Ô∏è Dur√©e : {results['duration_seconds']:.1f}s", extra={"module": "scripts"})
        ark_logger.info(f"üéØ Statut : {'‚úÖ SUCC√àS' if results['return_code'] == 0 else '‚ùå √âCHEC'}", extra={"module": "scripts"})
        ark_logger.info(f"üêç Python : {results['environment']['python_version'].split(, extra={"module": "scripts"})[0]}")
        ark_logger.info(f"üíª Plateforme : {results['environment']['platform']}", extra={"module": "scripts"})

        # Extraire m√©triques du stdout si possible
        stdout = results.get("stdout", "")
        if "ZeroIA d√©cision en" in stdout:
            ark_logger.info("\nüß† M√©triques ZeroIA :", extra={"module": "scripts"})
            for line in stdout.split("\n"):
                if "ZeroIA d√©cision en" in line:
                    ark_logger.info(f"  {line}", extra={"module": "scripts"})

        if "Circuit Breaker" in stdout:
            ark_logger.info("\n‚ö° M√©triques Circuit Breaker :", extra={"module": "scripts"})
            for line in stdout.split("\n"):
                if "Circuit Breaker" in line and "Latence" in line:
                    ark_logger.info(f"  {line}", extra={"module": "scripts"})

        if "Event Store" in stdout:
            ark_logger.info("\nüíæ M√©triques Event Store :", extra={"module": "scripts"})
            for line in stdout.split("\n"):
                if "Event Store" in line and "√©v√©nements" in line:
                    ark_logger.info(f"  {line}", extra={"module": "scripts"})

    except Exception as e:
        ark_logger.info(f"‚ùå Erreur lors de la g√©n√©ration du rapport : {e}", extra={"module": "scripts"})


def main():
    """Point d'entr√©e principal"""

    parser = argparse.ArgumentParser(description="Benchmarks performance Arkalia-LUNA Enhanced")
    parser.add_argument(
        "--output-dir",
        default="benchmark_results",
        help="Dossier de sortie des r√©sultats",
    )
    parser.add_argument(
        "--report-only",
        action="store_true",
        help="G√©n√©rer seulement le rapport (sans lancer les tests)",
    )

    args = parser.parse_args()

    try:
        if args.report_only:
            generate_summary_report(args.output_dir)
        else:
            success = run_performance_tests(args.output_dir)
            if success:
                generate_summary_report(args.output_dir)
            sys.exit(0 if success else 1)
    except Exception as e:
        ark_logger.info(f"‚ùå Erreur fatale : {e}", extra={"module": "scripts"})
        sys.exit(1)


if __name__ == "__main__":
    main()
