#!/usr/bin/env python3
# ðŸš€ scripts/arkalia_enhanced_integration.py
# IntÃ©gration complÃ¨te des recommandations Arkalia-LUNA Enhanced v3.0-phase1+

"""
ðŸŽ¯ INTÃ‰GRATION COMPLÃˆTE - Toutes tes recommandations implÃ©mentÃ©es

âœ… 1. RÃ©action automatique (7+ dÃ©cisions identiques â†’ pause cognitive)
âœ… 2. Timeline cognitive (Chronalia  # noqa: F401  JSONL)
âœ… 3. Mode quarantine cognitive
âœ… 4. Heatmap cognitive Grafana
âœ… 5. Mode Berserk/Recovery pour effondrements brutaux

Usage:
    python scripts/arkalia_enhanced_integration.py --demo
    python scripts/arkalia_enhanced_integration.py --integrate-with-zeroia
    python scripts/arkalia_enhanced_integration.py --generate-heatmap-data
"""

from core.ark_logger import ark_logger
import asyncio
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

# Configuration logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Ajout du chemin des modules
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from modules.sandozia.core.chronalia import Chronalia  # noqa: F401
    from modules.sandozia.core.cognitive_reactor import (  # noqa: F401,  # noqa: F401,
        CognitiveReactor,
        QuarantineReason,
        ReactionSeverity,
    )
    from modules.zeroia.event_store import (  # noqa: F401,  # noqa: F401,  # noqa: F401,  # noqa: F401,; noqa: F401# noqa: F401# noqa: F401# noqa: F401# noqa: F401# noqa: F401# noqa: F401
        EventStore,
        EventType,
    )
    from modules.zeroia.reason_loop_enhanced import (  # noqa: F401# noqa: F401# noqa: F401# noqa: F401# noqa: F401# noqa: F401
        reason_loop_enhanced_with_recovery,
    )
except ImportError as e:
    logger.error(f"âŒ Erreur import modules: {e}")
    logger.error("Assurez-vous d'Ãªtre dans le rÃ©pertoire arkalia-luna-pro")
    sys.exit(1)


class ArkaliaEnhancedEngine:
    """
    ðŸš€ Moteur Arkalia Enhanced - IntÃ©gration complÃ¨te

    Combine toutes tes recommandations :
    - CognitiveReactor  # noqa: F401  (rÃ©actions automatiques)
    - Chronalia  # noqa: F401  (timeline cognitive)
    - ZeroIA Enhanced (dÃ©cisions)
    - MÃ©triques pour Grafana heatmap
    """

    def __init__(self) -> None:
        self.cognitive_reactor = CognitiveReactor  # noqa: F401
        self.chronalia = Chronalia  # noqa: F401
        self.event_store = EventStore()  # noqa: F401

        # Ã‰tat systÃ¨me
        self.decision_pattern_count = 0
        self.last_decision = None
        self.global_stats = {
            "total_cycles": 0,
            "cognitive_reactions_triggered": 0,
            "berserk_activations": 0,
            "patterns_detected": 0,
        }

        logger.info("ðŸš€ ArkaliaEnhancedEngine initialisÃ©")

    async def run_enhanced_cycle(self, context: dict | None = None) -> dict:
        """
        ðŸŽ¯ CYCLE ENHANCED COMPLET - ImplÃ©mentation de tes recommandations

        Flux :
        1. DÃ©marrer cycle Chronalia  # noqa: F401
        2. Analyser contexte et dÃ©tecter patterns
        3. DÃ©cision ZeroIA Enhanced
        4. RÃ©actions automatiques (CognitiveReactor  # noqa: F401 )
        5. Enregistrer timeline
        6. MÃ©triques heatmap
        """

        # 1. DÃ©marrer cycle cognitif
        cycle_id = self.chronalia.start_cycle()

        # 2. Contexte par dÃ©faut si non fourni
        if not context:
            context = self._generate_demo_context()

        # 3. DÃ©cision ZeroIA Enhanced
        try:
            decision, confidence = reason_loop_enhanced_with_recovery()
            logger.info(f"ðŸ§  DÃ©cision ZeroIA: {decision} (confiance: {confidence})")
        except Exception as e:
            raise RuntimeError(f"Erreur d'intÃ©gration Arkalia: {e}") from e

        # 4. DÃ©tection pattern rÃ©pÃ©titif (TA RECOMMANDATION CLEF)
        if decision == self.last_decision:
            self.decision_pattern_count += 1
        else:
            self.decision_pattern_count = 1
            self.last_decision = decision

        # 5. Mise Ã  jour contexte avec rÃ©sultat
        enhanced_context = {
            **context,
            "zeroia_decision": decision,
            "confidence": confidence,
            "decision_pattern": ("identical" if self.decision_pattern_count >= 3 else "normal"),
            "pattern_repetition_count": self.decision_pattern_count,
            "cycle_id": cycle_id,
        }

        # 6. ðŸ”¥ RÃ‰ACTIONS AUTOMATIQUES (TA RECOMMANDATION 1)
        cognitive_reactions = await self.cognitive_reactor.check_and_react(
            enhanced_context, self.decision_pattern_count
        )

        # 7. Traitement rÃ©actions
        reaction_descriptions = []
        for reaction in cognitive_reactions:
            reaction_descriptions.append(f"{reaction.action}:{reaction.severity.value}")
            self.global_stats["cognitive_reactions_triggered"] += 1

            if reaction.severity == ReactionSeverity.BERSERK:
                self.global_stats["berserk_activations"] += 1
                logger.critical(f"ðŸš¨ MODE BERSERK DÃ‰CLENCHÃ‰: {reaction.action}")

        # 8. ðŸ•°ï¸ TIMELINE CHRONALIA (TA RECOMMANDATION 2)
        self.chronalia.complete_cycle(enhanced_context, reaction_descriptions)

        # 9. ðŸ” DÃ‰TECTION PATTERNS TEMPORELS
        patterns = self.chronalia.detect_patterns()
        self.global_stats["patterns_detected"] += len(patterns)

        # 10. MÃ©triques pour heatmap Grafana
        heatmap_data = self._generate_heatmap_metrics(enhanced_context, cognitive_reactions)

        # 11. Stats globales
        self.global_stats["total_cycles"] += 1

        # 12. RÃ©sultat complet
        result = {
            "cycle_id": cycle_id,
            "decision": decision,
            "confidence": confidence,
            "pattern_count": self.decision_pattern_count,
            "cognitive_reactions": reaction_descriptions,
            "patterns_detected": len(patterns),
            "quarantined_modules": list(self.cognitive_reactor.quarantined_modules.keys()),
            "berserk_mode": self.cognitive_reactor.berserk_mode_active,
            "global_stats": self.global_stats.copy(),
            "heatmap_data": heatmap_data,
            "timeline_recorded": True,
        }

        logger.info(f"âœ… Cycle Enhanced complÃ©tÃ©: {cycle_id}")
        return result

    def _generate_demo_context(self) -> dict:
        """GÃ©nÃ¨re un contexte de dÃ©mo rÃ©aliste"""
        import random

        # Simulation rÃ©aliste (dÃ©mo uniquement)
        base_cpu = 45 + random.randint(-15, 35)  # nosec B311  # 30-80% CPU
        base_ram = 40 + random.randint(-10, 30)  # nosec B311  # 30-70% RAM

        return {
            "timestamp": datetime.now().isoformat(),
            "system_cpu": base_cpu,
            "system_ram": base_ram,
            "reflexia_score": round(random.uniform(0.6, 1.0), 3),  # nosec B311
            "sandozia_health": round(random.uniform(0.7, 0.95), 3),  # nosec B311
            "contradiction": random.choice([False, False, False, True]),  # nosec B311  # 25% contradictions
            "modules_active": ["zeroia", "reflexia", "sandozia"],
            "quarantined_modules": [],
            "berserk_mode": False,
            "global_health_score": round(random.uniform(0.5, 0.9), 3),  # nosec B311
        }

    def _generate_heatmap_metrics(self, context: dict, reactions: list) -> dict:
        """
        ðŸ“Š GÃ‰NÃˆRE MÃ‰TRIQUES HEATMAP (TA RECOMMANDATION 4)

        Format pour Grafana :
        - Niveau de bruit des modules
        - RÃ©actions par type
        - SantÃ© globale
        """

        # Calcul niveau de bruit modules
        noise_level = (
            len(reactions) * 0.1
            + len(context.get("quarantined_modules", [])) * 0.2
            + (1 if context.get("contradiction", False) else 0) * 0.3
            + (1 if context.get("berserk_mode", False) else 0) * 0.5
        )

        return {
            "timestamp": datetime.now().isoformat(),
            "modules_noise_level": round(noise_level, 3),
            "cognitive_reactions_count": len(reactions),
            "quarantined_modules_count": len(context.get("quarantined_modules", [])),
            "contradiction_active": context.get("contradiction", False),
            "berserk_mode_active": context.get("berserk_mode", False),
            "global_health_score": context.get("global_health_score", 0.5),
            "confidence": context.get("confidence", 0.5),
            "cpu_usage": context.get("system_cpu", 50),
            "ram_usage": context.get("system_ram", 50),
        }

    async def run_stress_test(self, cycles: int = 20, force_patterns: bool = True):
        """ðŸ§ª Test de stress pour dÃ©clencher toutes les rÃ©actions"""

        logger.info(f"ðŸ§ª DÃ©but test de stress - {cycles} cycles")

        results = []

        for i in range(cycles):
            # Contexte de stress progressif
            stress_context = self._generate_demo_context()

            # Force des patterns rÃ©pÃ©titifs aprÃ¨s cycle 10
            if force_patterns and i > 10:
                stress_context.update(
                    {
                        "system_cpu": 85,  # CPU Ã©levÃ©
                        "system_ram": 80,  # RAM Ã©levÃ©e
                        "reflexia_score": 0.3,  # Score faible
                        "sandozia_health": 0.2,  # SantÃ© dÃ©gradÃ©e
                        "contradiction": True,  # Force contradictions
                        "global_health_score": 0.15,  # Proche seuil berserk
                    }
                )

            # Cycle enhanced
            result = await self.run_enhanced_cycle(stress_context)
            results.append(result)

            # Log progression
            if result["cognitive_reactions"]:
                logger.warning(
                    f"ðŸ”¥ Cycle {i + 1}: RÃ©actions dÃ©clenchÃ©es: {result['cognitive_reactions']}"
                )

            if result["berserk_mode"]:
                logger.critical(f"ðŸš¨ Cycle {i + 1}: MODE BERSERK ACTIVÃ‰!")

            # DÃ©lai entre cycles
            await asyncio.sleep(0.1)

        # RÃ©sumÃ© final
        total_reactions = sum(len(r["cognitive_reactions"]) for r in results)
        berserk_count = sum(1 for r in results if r["berserk_mode"])

        logger.info("ðŸŽ¯ Test de stress terminÃ©:")
        logger.info(f"   - {cycles} cycles exÃ©cutÃ©s")
        logger.info(f"   - {total_reactions} rÃ©actions dÃ©clenchÃ©es")
        logger.info(f"   - {berserk_count} activations berserk")
        logger.info(f"   - {len(self.cognitive_reactor.quarantined_modules)} modules en quarantine")

        return results

    def export_timeline_and_heatmap(self, hours_back: int = 1) -> dict[str, str]:
        """ðŸ“¤ Exporte timeline et donnÃ©es heatmap"""

        # Export timeline Chronalia  # noqa: F401
        timeline_file = self.chronalia.export_timeline(hours_back)

        # Export donnÃ©es heatmap pour Grafana
        heatmap_data = self.chronalia.get_heatmap_data(hours_back)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        heatmap_file = Path(f"state/chronalia/heatmap_data_{timestamp}.json")

        with heatmap_file.open("w") as f:
            json.dump(heatmap_data, f, indent=2, ensure_ascii=False)

        logger.info("ðŸ“¤ Exports terminÃ©s:")
        logger.info(f"   - Timeline: {timeline_file}")
        logger.info(f"   - Heatmap: {heatmap_file}")

        return {"timeline_file": str(timeline_file), "heatmap_file": str(heatmap_file)}

    def get_quarantine_status(self) -> dict:
        """ðŸ”’ Ã‰tat complet des quarantines"""
        return self.cognitive_reactor.get_quarantine_status()

    def get_system_summary(self) -> dict:
        """ðŸ“Š RÃ©sumÃ© systÃ¨me complet"""
        return {
            "arkalia_version": "v3.0-phase1",
            "enhanced_features_active": True,
            "global_stats": self.global_stats,
            "quarantined_modules": list(self.cognitive_reactor.quarantined_modules.keys()),
            "berserk_mode_active": self.cognitive_reactor.berserk_mode_active,
            "recent_cycles_count": len(self.chronalia.recent_cycles),
            "last_decision": self.last_decision,
            "pattern_count": self.decision_pattern_count,
            "cognitive_reactor_active": True,
            "chronalia_active": True,
            "timeline_file": str(self.chronalia.cycles_file),
        }


# ðŸš€ FONCTIONS UTILITAIRES
async def demo_complete_workflow():
    """ðŸŽ¯ DÃ©mo workflow complet des recommandations"""

    ark_logger.info("\nðŸš€ DÃ‰MO ARKALIA-LUNA ENHANCED v3.0-phase1+", extra={"module": "scripts"})
    ark_logger.info("=" * 60, extra={"module": "scripts"})
    ark_logger.info("ðŸŽ¯ ImplÃ©mentation complÃ¨te de tes recommandations :", extra={"module": "scripts"})
    ark_logger.info("   âœ… 1. RÃ©actions automatiques (7+ rÃ©pÃ©titions â†’ pause)", extra={"module": "scripts"})
    ark_logger.info("   âœ… 2. Timeline cognitive (Chronalia  # noqa: F401  JSONL)", extra={"module": "scripts"})
    ark_logger.info("   âœ… 3. Mode quarantine cognitive", extra={"module": "scripts"})
    ark_logger.info("   âœ… 4. DonnÃ©es heatmap Grafana", extra={"module": "scripts"})
    ark_logger.info("   âœ… 5. Mode Berserk/Recovery pour panics", extra={"module": "scripts"})
    ark_logger.info("")

    engine = ArkaliaEnhancedEngine()

    # Test cycles normaux
    ark_logger.info("ðŸ”„ ExÃ©cution 5 cycles normaux...", extra={"module": "scripts"})
    for i in range(5):
        result = await engine.run_enhanced_cycle()
<<<<<<< HEAD
        ark_logger.info(f"   Cycle {i+1}: {result['decision']} (confiance: {result['confidence']:.2f}, extra={"module": "scripts"})")
=======
        print(f"   Cycle {i + 1}: {result['decision']} (confiance: {result['confidence']:.2f})")
>>>>>>> dev-migration

    ark_logger.info("")

    # Test de stress pour dÃ©clencher rÃ©actions
    ark_logger.info("ðŸ§ª Test de stress (patterns rÃ©pÃ©titifs + dÃ©gradation)...", extra={"module": "scripts"})
    await engine.run_stress_test(cycles=15, force_patterns=True)

    ark_logger.info("")

    # RÃ©sumÃ© final
    summary = engine.get_system_summary()
    ark_logger.info("ðŸ“Š RÃ‰SUMÃ‰ FINAL:", extra={"module": "scripts"})
    ark_logger.info(f"   - Cycles totaux: {summary['global_stats']['total_cycles']}", extra={"module": "scripts"})
    ark_logger.info(f"   - RÃ©actions dÃ©clenchÃ©es: {summary['global_stats']['cognitive_reactions_triggered']}", extra={"module": "scripts"})
    ark_logger.info(f"   - Activations berserk: {summary['global_stats']['berserk_activations']}", extra={"module": "scripts"})
    ark_logger.info(f"   - Modules en quarantine: {len(summary['quarantined_modules'], extra={"module": "scripts"})}")
    ark_logger.info(f"   - Patterns dÃ©tectÃ©s: {summary['global_stats']['patterns_detected']}", extra={"module": "scripts"})

    # Export timeline et heatmap
    ark_logger.info("\nðŸ“¤ Export timeline et donnÃ©es heatmap...", extra={"module": "scripts"})
    exports = engine.export_timeline_and_heatmap()
    ark_logger.info(f"   - Timeline: {exports['timeline_file']}", extra={"module": "scripts"})
    ark_logger.info(f"   - Heatmap: {exports['heatmap_file']}", extra={"module": "scripts"})

    ark_logger.info("\nðŸŽ‰ DÃ‰MO TERMINÃ‰E - Toutes tes recommandations fonctionnelles !", extra={"module": "scripts"})
    ark_logger.info(f"ðŸ“‹ Timeline disponible: {summary['timeline_file']}", extra={"module": "scripts"})

    return engine


async def integrate_with_zeroia():
    """ðŸ”— IntÃ©gration avec le reason_loop ZeroIA existant"""

    ark_logger.info("ðŸ”— IntÃ©gration avec ZeroIA Enhanced...", extra={"module": "scripts"})

    engine = ArkaliaEnhancedEngine()

    # Simulation intÃ©gration
    for i in range(10):
        context = {
            "real_integration": True,
            "zeroia_call": True,
            "timestamp": datetime.now().isoformat(),
        }

        result = await engine.run_enhanced_cycle(context)

        if result["cognitive_reactions"]:
<<<<<<< HEAD
            ark_logger.info(f"ðŸ”¥ RÃ©actions automatiques cycle {i+1}: {result['cognitive_reactions']}", extra={"module": "scripts"})
=======
            print(f"ðŸ”¥ RÃ©actions automatiques cycle {i + 1}: {result['cognitive_reactions']}")
>>>>>>> dev-migration

    ark_logger.info("âœ… IntÃ©gration ZeroIA testÃ©e avec succÃ¨s", extra={"module": "scripts"})


def generate_heatmap_sample():
    """ðŸ“Š GÃ©nÃ¨re Ã©chantillon donnÃ©es heatmap pour Grafana"""

    ark_logger.info("ðŸ“Š GÃ©nÃ©ration donnÃ©es heatmap pour Grafana...", extra={"module": "scripts"})

    chronalia = Chronalia  # noqa: F401
    heatmap_data = chronalia.get_heatmap_data(hours_back=24)

    output_file = Path("state/chronalia/grafana_heatmap_sample.json")
    with output_file.open("w") as f:
        json.dump(heatmap_data, f, indent=2, ensure_ascii=False)

    ark_logger.info(f"ðŸ“Š DonnÃ©es heatmap gÃ©nÃ©rÃ©es: {output_file}", extra={"module": "scripts"})
    ark_logger.info(f"   - {len(heatmap_data['heatmap_data'], extra={"module": "scripts"})} points de donnÃ©es")
    ark_logger.info(f"   - RÃ©solution: {heatmap_data['summary']['resolution_minutes']} minutes", extra={"module": "scripts"})


# ðŸŽ¯ MAIN
async def main():
    """Point d'entrÃ©e principal"""

    import argparse

    parser = argparse.ArgumentParser(description="ðŸš€ Arkalia-LUNA Enhanced Integration")
    parser.add_argument("--demo", action="store_true", help="DÃ©mo workflow complet")
    parser.add_argument(
        "--integrate-with-zeroia", action="store_true", help="Test intÃ©gration ZeroIA"
    )
    parser.add_argument(
        "--generate-heatmap-data", action="store_true", help="GÃ©nÃ¨re donnÃ©es heatmap"
    )
    parser.add_argument("--stress-test", type=int, help="Test de stress (nombre de cycles)")

    args = parser.parse_args()

    if args.demo:
        await demo_complete_workflow()
    elif args.integrate_with_zeroia:
        await integrate_with_zeroia()
    elif args.generate_heatmap_data:
        generate_heatmap_sample()
    elif args.stress_test:
        engine = ArkaliaEnhancedEngine()
        await engine.run_stress_test(cycles=args.stress_test)
    else:
        # Par dÃ©faut : dÃ©mo
        await demo_complete_workflow()


if __name__ == "__main__":
    asyncio.run(main())
