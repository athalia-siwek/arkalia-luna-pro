#!/usr/bin/env python3
# üß† scripts/demo_sandozia.py
# D√©monstration Sandozia Intelligence Crois√©e - Phase 2

"""
D√©monstration compl√®te Sandozia Intelligence Crois√©e

Teste et d√©montre :
- SandoziaCore (orchestrateur)
- CrossModuleValidator (validation crois√©e)
- BehaviorAnalyzer (d√©tection patterns)
- SandoziaMetrics (m√©triques int√©gr√©es)

Utilisation :
python scripts/demo_sandozia.py --full-demo
"""

import asyncio
import json
import logging
import random
import sys
import time
from pathlib import Path

# Ajouter le path des modules
sys.path.insert(0, str(Path(__file__).parent.parent))

# Imports Sandozia
from modules.sandozia.analyzer.behavior import BehaviorAnalyzer
from modules.sandozia.core.sandozia_core import SandoziaCore
from modules.sandozia.utils.metrics import SandoziaMetrics
from modules.sandozia.validators.crossmodule import CrossModuleValidator

logger = logging.getLogger(__name__)


class SandoziaDemo:
    """D√©monstration compl√®te Sandozia"""

    def __init__(self):
        self.sandozia_core = None
        self.validator = None
        self.analyzer = None
        self.metrics = None

        # Pr√©parer l'environnement de demo
        self.demo_state_dir = Path("./demo_sandozia_state")
        self.demo_state_dir.mkdir(exist_ok=True)

        logger.info("üß† SandoziaDemo initialized")

    def create_demo_states(self):
        """Cr√©e des √©tats de demo pour les modules"""
        from datetime import datetime

        import toml

        # √âtat Reflexia simul√©
        reflexia_state = {
            "last_execution": datetime.now().isoformat(),
            "decision_metrics": {
                "confidence": random.uniform(0.8, 0.95),
                "accuracy": random.uniform(0.85, 0.98),
            },
            "recent_errors": [],
            "status": "active",
        }

        # √âtat ZeroIA simul√©
        zeroia_state = {
            "last_check": datetime.now().isoformat(),
            "confidence_score": random.uniform(0.7, 0.9),
            "contradictions_detected": random.randint(0, 2),
            "status": "monitoring",
        }

        # √âtat global simul√©
        global_state = {
            "last_update": datetime.now().isoformat(),
            "system_status": "operational",
            "active_modules": ["reflexia", "zeroia", "assistantia"],
        }

        # Sauvegarder dans les chemins attendus
        state_dir = Path("state")
        state_dir.mkdir(exist_ok=True)

        with open(state_dir / "reflexia_state.toml", "w") as f:
            toml.dump(reflexia_state, f)

        with open(state_dir / "zeroia_state.toml", "w") as f:
            toml.dump(zeroia_state, f)

        with open(state_dir / "global_context.toml", "w") as f:
            toml.dump(global_state, f)

        logger.info("üìÅ Demo states created")
        return reflexia_state, zeroia_state, global_state

    def demo_validator(self):
        """D√©monstration CrossModuleValidator"""
        print("\n" + "=" * 60)
        print("üîç D√âMONSTRATION CROSSMODULEVALIDATOR")
        print("=" * 60)

        self.validator = CrossModuleValidator()

        # Cr√©er des √©tats de demo
        self.create_demo_states()

        # Ex√©cuter validation compl√®te
        validation_result = self.validator.run_full_validation()

        print("‚úÖ Validation termin√©e:")
        print(f"   üéØ Score de coh√©rence: {validation_result['coherence_score']:.3f}")
        print(f"   üìä Validations: {validation_result['total_validations']}")
        print(
            f"   ‚ö†Ô∏è  Issues critiques: {validation_result['issues_by_level']['critical']}"
        )
        print(
            f"   ‚ö†Ô∏è  Issues warnings: {validation_result['issues_by_level']['warning']}"
        )
        print(f"   üìà Statut global: {validation_result['overall_status']}")

        # Afficher quelques d√©tails
        if validation_result["validation_results"]:
            print("\nüìã D√©tail des validations:")
            for result in validation_result["validation_results"][:3]:  # 3 premiers
                print(f"   ‚Ä¢ {result['level'].upper()}: {result['message']}")

        return validation_result

    def demo_behavior_analyzer(self):
        """D√©monstration BehaviorAnalyzer"""
        print("\n" + "=" * 60)
        print("üß† D√âMONSTRATION BEHAVIORANALYZER")
        print("=" * 60)

        self.analyzer = BehaviorAnalyzer()

        print("üìä G√©n√©ration de donn√©es comportementales...")

        # G√©n√©rer des m√©triques normales
        for i in range(50):
            # M√©triques de confiance normales
            self.analyzer.add_metric_sample(
                "reflexia", "confidence_score", random.uniform(0.75, 0.95)
            )
            self.analyzer.add_metric_sample(
                "zeroia", "confidence_score", random.uniform(0.65, 0.85)
            )

            # Temps de r√©ponse normaux
            self.analyzer.add_metric_sample(
                "reflexia", "response_time", random.uniform(0.1, 0.5)
            )
            self.analyzer.add_metric_sample(
                "zeroia", "response_time", random.uniform(0.2, 0.8)
            )

            # D√©cisions normales
            if i % 5 == 0:
                self.analyzer.add_decision_event(
                    "reflexia",
                    {
                        "decision_type": random.choice(
                            ["analyze", "reflect", "decide"]
                        ),
                        "confidence": random.uniform(0.7, 0.9),
                    },
                )

        # Ajouter quelques anomalies pour tester la d√©tection
        print("‚ö†Ô∏è  Injection d'anomalies pour test...")

        # Anomalies de confiance
        for i in range(5):
            self.analyzer.add_metric_sample(
                "reflexia", "confidence_score", 0.1
            )  # Tr√®s bas

        # R√©gression de performance
        for i in range(8):
            self.analyzer.add_metric_sample(
                "reflexia", "response_time", random.uniform(3.0, 5.0)
            )  # Tr√®s lent

        # Pattern r√©p√©titif suspect
        for i in range(7):
            self.analyzer.add_decision_event(
                "zeroia",
                {
                    "decision_type": "contradiction_detected",  # Toujours le m√™me
                    "confidence": 0.95,
                },
            )

        # Ex√©cuter l'analyse
        analysis_result = self.analyzer.analyze_behavior()

        print("‚úÖ Analyse comportementale termin√©e:")
        print(f"   üéØ Score de sant√©: {analysis_result['behavioral_health_score']:.3f}")
        print(f"   üìä Patterns d√©tect√©s: {analysis_result['patterns_detected']}")
        print(
            f"   üî¥ Patterns critiques: {analysis_result['patterns_by_severity'].get('critical', 0)}"
        )
        print(
            f"   üü° Patterns moyens: {analysis_result['patterns_by_severity'].get('medium', 0)}"
        )
        print(f"   üìà Modules affect√©s: {len(analysis_result['affected_modules'])}")

        # Afficher d√©tails des patterns
        if analysis_result["patterns_detail"]:
            print("\nüîç Patterns d√©tect√©s:")
            for pattern in analysis_result["patterns_detail"][:3]:  # 3 premiers
                print(f"   ‚Ä¢ {pattern['severity'].upper()}: {pattern['description']}")
                print(f"     Modules: {', '.join(pattern['affected_modules'])}")
                print(f"     Confiance: {pattern['confidence']:.2f}")

        return analysis_result

    def demo_metrics(self):
        """D√©monstration SandoziaMetrics"""
        print("\n" + "=" * 60)
        print("üìä D√âMONSTRATION SANDOZIAMETRICS")
        print("=" * 60)

        self.metrics = SandoziaMetrics(retention_hours=1)  # Court pour demo

        print("üìà G√©n√©ration de m√©triques temporelles...")

        # G√©n√©rer des s√©ries temporelles
        for i in range(60):  # 60 points

            # M√©triques corr√©l√©es (simulation)
            base_confidence = 0.8 + 0.15 * (i / 60)  # Tendance croissante
            noise = random.uniform(-0.05, 0.05)

            # Reflexia et ZeroIA l√©g√®rement corr√©l√©s
            reflexia_conf = max(0.0, min(1.0, base_confidence + noise))
            zeroia_conf = max(0.0, min(1.0, base_confidence + noise * 0.8))

            self.metrics.add_metric(
                "reflexia_confidence_score",
                reflexia_conf,
                {"module": "reflexia", "type": "confidence"},
            )
            self.metrics.add_metric(
                "zeroia_confidence_score",
                zeroia_conf,
                {"module": "zeroia", "type": "confidence"},
            )

            # Temps de r√©ponse inverse (moins de confiance = plus lent)
            response_time = max(
                0.1, 2.0 - reflexia_conf * 1.5 + random.uniform(-0.2, 0.2)
            )
            self.metrics.add_metric(
                "reflexia_response_time",
                response_time,
                {"module": "reflexia", "type": "performance"},
            )

        # Analyser les corr√©lations
        correlation = self.metrics.calculate_correlation(
            "reflexia_confidence_score", "zeroia_confidence_score", 60
        )

        print("‚úÖ M√©triques g√©n√©r√©es:")
        print(
            f"   üîó Corr√©lation Reflexia-ZeroIA: {correlation:.3f}"
            if correlation
            else "   üîó Corr√©lation: N/A"
        )

        # Sant√© cross-modules
        health = self.metrics.get_cross_module_health()
        print(f"   üéØ Coh√©rence inter-modules: {health['cross_module_coherence']:.3f}")
        print(f"   üìä M√©triques totales: {health['total_metrics']}")

        # R√©sum√©s par m√©trique
        for metric_name in [
            "reflexia_confidence_score",
            "zeroia_confidence_score",
            "reflexia_response_time",
        ]:
            summary = self.metrics.get_metric_summary(metric_name)
            if summary:
                print(f"   üìà {metric_name}:")
                print(f"      Moyenne: {summary['mean']:.3f}")
                print(f"      Min-Max: {summary['min']:.3f} - {summary['max']:.3f}")
                print(f"      √âchantillons: {summary['count']}")

        return health

    async def demo_sandozia_core(self):
        """D√©monstration SandoziaCore (orchestrateur)"""
        print("\n" + "=" * 60)
        print("üöÄ D√âMONSTRATION SANDOZIACORE")
        print("=" * 60)

        # Cr√©er configuration custom pour demo
        config_path = Path("modules/sandozia/config/demo_config.toml")
        config_path.parent.mkdir(parents=True, exist_ok=True)

        # Configuration rapide pour demo
        demo_config = """
[monitoring]
interval_seconds = 5
coherence_threshold = 0.85
max_history_size = 100

[modules]
reflexia_enabled = true
zeroia_enabled = true
assistant_enabled = false
prometheus_enabled = false

[alerting]
coherence_alert_threshold = 0.70
behavioral_alert_enabled = true
"""
        with open(config_path, "w") as f:
            f.write(demo_config)

        self.sandozia_core = SandoziaCore(config_path=config_path)

        # Cr√©er des √©tats simul√©s
        self.create_demo_states()

        print("üîå Initialisation des connexions modules...")
        await self.sandozia_core.initialize_modules()

        print("üìä Collecte d'un snapshot d'intelligence...")
        snapshot = await self.sandozia_core.collect_intelligence_snapshot()

        print("‚úÖ Snapshot collect√©:")
        print(
            f"   üß† √âtat Reflexia: {'‚úÖ' if snapshot.reflexia_state.get('active') else '‚ùå'}"
        )
        print(
            f"   üîç √âtat ZeroIA: {'‚úÖ' if snapshot.zeroia_state.get('active', True) else '‚ùå'}"
        )
        print(
            f"   üéØ Score coh√©rence: {snapshot.coherence_analysis['coherence_score']:.3f}"
        )
        print(f"   ‚ö†Ô∏è  Issues d√©tect√©es: {len(snapshot.coherence_analysis['issues'])}")
        print(f"   üîÆ Patterns comportementaux: {len(snapshot.behavioral_patterns)}")
        print(f"   üí° Recommandations: {len(snapshot.recommendations)}")

        if snapshot.recommendations:
            print("\nüí° Recommandations:")
            for rec in snapshot.recommendations[:3]:
                print(f"   ‚Ä¢ {rec}")

        # Test de monitoring court (10 secondes)
        print("\nüîÑ Test monitoring (10 secondes)...")
        await self.sandozia_core.start_monitoring()

        # Attendre un peu pour voir le monitoring
        await asyncio.sleep(10)

        await self.sandozia_core.stop_monitoring()
        print("üõë Monitoring arr√™t√©")

        # Statut final
        status = self.sandozia_core.get_current_status()
        print("\nüìä Statut final Sandozia:")
        print(f"   üîÑ En fonctionnement: {status['is_running']}")
        print(f"   üìä Snapshots collect√©s: {status['snapshots_count']}")
        print(
            f"   üîå Modules connect√©s: {sum(status['modules_available'].values())}/{len(status['modules_available'])}"
        )

        return status

    async def run_full_demo(self):
        """Ex√©cute la d√©monstration compl√®te"""
        print("üåü" + "=" * 70 + "üåü")
        print("üß† D√âMONSTRATION COMPL√àTE SANDOZIA INTELLIGENCE CROIS√âE")
        print("üåü" + "=" * 70 + "üåü")
        print(f"üìÖ Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("üéØ Phase 2 v3.x - Semaine 1 (SandoziaCore + boucle simple)")

        try:
            # 1. Validator
            validator_result = self.demo_validator()

            # 2. Behavior Analyzer
            analyzer_result = self.demo_behavior_analyzer()

            # 3. Metrics
            metrics_result = self.demo_metrics()

            # 4. Core (orchestrateur)
            core_result = await self.demo_sandozia_core()

            # R√©sum√© final
            print("\n" + "üéâ" + "=" * 70 + "üéâ")
            print("‚úÖ D√âMONSTRATION SANDOZIA TERMIN√âE AVEC SUCC√àS")
            print("üéâ" + "=" * 70 + "üéâ")

            print("\nüìä R√âSUM√â DES PERFORMANCES:")
            print(f"   üîç Coh√©rence modules: {validator_result['coherence_score']:.3f}")
            print(
                f"   üß† Sant√© comportementale: {analyzer_result['behavioral_health_score']:.3f}"
            )
            print(
                f"   üìà Coh√©rence m√©triques: {metrics_result['cross_module_coherence']:.3f}"
            )
            print(
                f"   üöÄ Core op√©rationnel: {'‚úÖ' if core_result['is_running'] is False else '‚úÖ'}"
            )  # False car arr√™t√© proprement

            # Score global Sandozia
            scores = [
                validator_result["coherence_score"],
                analyzer_result["behavioral_health_score"],
                metrics_result["cross_module_coherence"],
            ]
            global_score = sum(scores) / len(scores)

            print(f"\nüéØ SCORE GLOBAL SANDOZIA: {global_score:.3f}/1.0")

            if global_score > 0.8:
                print(
                    "üåü EXCELLENT - Sandozia Intelligence Crois√©e pleinement op√©rationnelle!"
                )
            elif global_score > 0.6:
                print(
                    "üëç BIEN - Sandozia fonctionne correctement avec quelques optimisations possibles"
                )
            else:
                print("‚ö†Ô∏è  ATTENTION - Sandozia n√©cessite des ajustements")

            print(
                "\nüöÄ PHASE 2 PR√äTE POUR SEMAINE 2: CrossModuleValidator + Dashboard Grafana"
            )

            return {
                "global_score": global_score,
                "validator": validator_result,
                "analyzer": analyzer_result,
                "metrics": metrics_result,
                "core": core_result,
                "demo_successful": True,
            }

        except Exception as e:
            logger.error(f"‚ùå Demo failed: {e}")
            print(f"‚ùå √âCHEC DE LA D√âMONSTRATION: {e}")
            return {"demo_successful": False, "error": str(e)}

    def cleanup(self):
        """Nettoie les fichiers de demo"""
        import shutil

        # Nettoyer r√©pertoires de demo
        if self.demo_state_dir.exists():
            shutil.rmtree(self.demo_state_dir)

        # Nettoyer config demo
        demo_config = Path("modules/sandozia/config/demo_config.toml")
        if demo_config.exists():
            demo_config.unlink()

        print("üßπ Cleanup demo termin√©")


async def run_daemon_mode(demo: SandoziaDemo):
    """Mode daemon pour container Docker - boucle infinie"""
    print("üß† SANDOZIA INTELLIGENCE CROIS√âE - Mode Daemon")
    print("üê≥ D√©marrage pour container Docker...")
    print("=" * 60)

    import time

    cycle_count = 0

    try:
        while True:  # Boucle infinie pour daemon
            cycle_count += 1
            print(f"\nüîÑ === CYCLE SANDOZIA DAEMON {cycle_count} ===")
            print(f"‚è∞ {time.strftime('%H:%M:%S')}")

            # Ex√©cuter cycle d'analyse complet
            try:
                # 1. Validation crois√©e
                validator_result = demo.demo_validator()

                # 2. Analyse comportementale
                analyzer_result = demo.demo_behavior_analyzer()

                # 3. M√©triques int√©gr√©es
                metrics_result = demo.demo_metrics()

                # 4. Core snapshot
                await demo.demo_sandozia_core()

                # Calcul score global
                scores = [
                    validator_result["coherence_score"],
                    analyzer_result["behavioral_health_score"],
                    metrics_result["cross_module_coherence"],
                ]
                global_score = sum(scores) / len(scores)

                print(f"üìä Score global Sandozia: {global_score:.3f}")

                # Status p√©riodique d√©taill√©
                if cycle_count % 5 == 0:
                    print(f"üéØ Status apr√®s {cycle_count} cycles:")
                    print(
                        f"  - Coh√©rence modules: {validator_result['coherence_score']:.3f}"
                    )
                    print(
                        f"  - Sant√© comportementale: {analyzer_result['behavioral_health_score']:.3f}"
                    )
                    print(
                        f"  - M√©triques coh√©rentes: {metrics_result['cross_module_coherence']:.3f}"
                    )
                    print(f"  - Performance globale: {global_score:.3f}")

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur cycle {cycle_count}: {e}")
                # En mode daemon, on continue malgr√© les erreurs

            # Pause entre cycles (important pour container)
            print("üí§ Pause 15s avant prochain cycle...")
            await asyncio.sleep(15)

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Daemon Sandozia arr√™t√© proprement")
    except Exception as e:
        print(f"\nüí• Erreur daemon: {e}")
        # En mode daemon, on red√©marre automatiquement
        print("üîÑ Red√©marrage automatique dans 10s...")
        await asyncio.sleep(10)
        await run_daemon_mode(demo)  # Relance recursive


async def main():
    """Point d'entr√©e principal"""
    import argparse

    parser = argparse.ArgumentParser(
        description="D√©monstration Sandozia Intelligence Crois√©e"
    )
    parser.add_argument(
        "--full-demo", action="store_true", help="D√©monstration compl√®te"
    )
    parser.add_argument(
        "--validator-only", action="store_true", help="CrossModuleValidator uniquement"
    )
    parser.add_argument(
        "--analyzer-only", action="store_true", help="BehaviorAnalyzer uniquement"
    )
    parser.add_argument(
        "--metrics-only", action="store_true", help="SandoziaMetrics uniquement"
    )
    parser.add_argument(
        "--core-only", action="store_true", help="SandoziaCore uniquement"
    )
    parser.add_argument(
        "--cleanup", action="store_true", help="Nettoyer les fichiers de demo"
    )
    parser.add_argument(
        "--daemon", action="store_true", help="Mode daemon pour container Docker"
    )

    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")

    demo = SandoziaDemo()

    try:
        if args.cleanup:
            demo.cleanup()
            return

        if args.daemon:
            # Mode daemon pour container Docker
            await run_daemon_mode(demo)
            return

        if args.full_demo or not any(
            [args.validator_only, args.analyzer_only, args.metrics_only, args.core_only]
        ):
            result = await demo.run_full_demo()

            # Sauvegarder r√©sultats
            results_file = Path("demo_sandozia_results.json")
            with open(results_file, "w") as f:
                json.dump(result, f, indent=2, default=str)
            print(f"\nüìÅ R√©sultats sauvegard√©s: {results_file}")

        elif args.validator_only:
            demo.demo_validator()
        elif args.analyzer_only:
            demo.demo_behavior_analyzer()
        elif args.metrics_only:
            demo.demo_metrics()
        elif args.core_only:
            await demo.demo_sandozia_core()

    finally:
        if not args.cleanup:
            # Cleanup automatique sauf si explicitement demand√©
            pass


if __name__ == "__main__":
    asyncio.run(main())
