---
name: ðŸš€ Tests de Performance

on:
  push:
    branches: [ main, develop, dev-migration, refonte-stable ]
  pull_request:
    branches: [ main, develop, dev-migration, refonte-stable ]
  schedule:
    # Tests de performance quotidiens Ã  2h du matin
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: "3.10"
  PERFORMANCE_TIMEOUT: 1800  # 30 minutes

# Permissions pour Ã©viter les erreurs de sÃ©curitÃ©
permissions:
  contents: read
  actions: read

jobs:
  # ðŸš€ Tests de performance complets
  performance-tests:
    name: ðŸ“Š Tests de Performance Complets
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      matrix:
        python-version: ["3.10"]
        test-suite: ["zeroia", "api", "integration"]
      fail-fast: false
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-benchmark pytest-timeout
          pip install aiohttp requests locust

      - name: ðŸ§¹ Clean performance artifacts
        run: |
          find . -name "._*" -delete
          find . -name ".DS_Store" -delete
          find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
          rm -rf .benchmarks/ performance-results/

      - name: ðŸ³ Setup Docker for performance tests
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            image=moby/buildkit:v0.12.0

      - name: ðŸ³ Start services for performance testing
        run: |
          echo "ðŸš€ DÃ©marrage des services pour tests de performance..."
          docker compose up -d --remove-orphans
          sleep 60

      - name: ðŸ¥ Health check before performance tests
        run: |
          echo "ðŸ¥ VÃ©rification santÃ© avant tests de performance..."

          # VÃ©rification des services critiques
          for service in "8000/health" "8000/zeroia/health" "8000/reflexia/health"; do
            echo "ðŸ” VÃ©rification $service..."
            for i in {1..10}; do
              if curl -f -s "http://localhost:$service" > /dev/null; then
                echo "âœ… $service disponible"
                break
              else
                echo "â³ Tentative $i/10 - $service non disponible"
                sleep 10
              fi
            done
          done

      - name: ðŸ§ª Run Performance Tests - ${{ matrix.test-suite }}
        run: |
          echo "ðŸ§ª ExÃ©cution des tests de performance - ${{ matrix.test-suite }}..."

          case "${{ matrix.test-suite }}" in
            "zeroia")
              echo "ðŸ“Š Tests de performance ZeroIA..."
              pytest tests/performance/zeroia/test_zeroia_performance.py::test_zeroia_decision_time_under_2s -v --benchmark-only
              pytest tests/performance/zeroia/test_zeroia_performance.py::test_circuit_breaker_latency_under_10ms -v --benchmark-only
              pytest tests/performance/zeroia/test_zeroia_performance.py::test_performance_regression_detection -v --benchmark-only
              ;;
            "api")
              echo "ðŸ“Š Tests de performance API..."
              pytest tests/performance/api/ -v --benchmark-only --timeout=300 || echo "âš ï¸ Tests API terminÃ©s avec avertissements"
              ;;
            "integration")
              echo "ðŸ“Š Tests de performance intÃ©gration..."
              pytest tests/performance/integration/ -v --benchmark-only --timeout=600 || echo "âš ï¸ Tests intÃ©gration terminÃ©s avec avertissements"
              ;;
          esac

      - name: ðŸ“Š Generate performance metrics
        run: |
          echo "ðŸ“Š GÃ©nÃ©ration des mÃ©triques de performance..."

          # Collecte des mÃ©triques systÃ¨me
          echo "ðŸ” MÃ©triques systÃ¨me:" > performance-metrics-${{ matrix.test-suite }}.md
          echo "- CPU: $(top -l 1 | grep 'CPU usage' | awk '{print \$3}')" >> performance-metrics-${{ matrix.test-suite }}.md
          echo "- MÃ©moire: $(vm_stat | grep 'Pages free' | awk '{print \$3}') pages libres" >> performance-metrics-${{ matrix.test-suite }}.md
          echo "- Disque: $(df -h / | awk 'NR==2 {print \$4}') libres" >> performance-metrics-${{ matrix.test-suite }}.md

          # Collecte des mÃ©triques Docker
          echo "" >> performance-metrics-${{ matrix.test-suite }}.md
          echo "ðŸ³ MÃ©triques Docker:" >> performance-metrics-${{ matrix.test-suite }}.md
          docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}" >> performance-metrics-${{ matrix.test-suite }}.md

      - name: ðŸ“Š Run load tests with Locust
        run: |
          echo "ðŸ“Š Tests de charge avec Locust..."

                    # CrÃ©ation d'un script Locust simple si nÃ©cessaire
          if [ ! -f "locustfile.py" ]; then
            echo 'from locust import HttpUser, task, between' > locustfile.py
            echo '' >> locustfile.py
            echo 'class ArkaliaUser(HttpUser):' >> locustfile.py
            echo '    wait_time = between(1, 3)' >> locustfile.py
            echo '' >> locustfile.py
            echo '    @task(3)' >> locustfile.py
            echo '    def health_check(self):' >> locustfile.py
            echo '        self.client.get("/health")' >> locustfile.py
            echo '' >> locustfile.py
            echo '    @task(2)' >> locustfile.py
            echo '    def zeroia_decision(self):' >> locustfile.py
            echo '        self.client.get("/zeroia/decision")' >> locustfile.py
            echo '' >> locustfile.py
            echo '    @task(1)' >> locustfile.py
            echo '    def reflexia_health(self):' >> locustfile.py
            echo '        self.client.get("/reflexia/health")' >> locustfile.py
          fi

          # ExÃ©cution des tests de charge
          locust -f locustfile.py --headless --users 10 --spawn-rate 2 --run-time 60s --html=load-test-report-${{ matrix.test-suite }}.html || echo "âš ï¸ Tests de charge terminÃ©s avec avertissements"

      - name: ðŸ“‹ Upload performance artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results-${{ matrix.test-suite }}
          path: |
            .benchmarks/
            performance-metrics-${{ matrix.test-suite }}.md
            load-test-report-${{ matrix.test-suite }}.html
            performance-results/
          retention-days: 30

      - name: ðŸ³ Stop services
        if: always()
        run: |
          echo "ðŸ›‘ ArrÃªt des services..."
          docker compose down --remove-orphans
          docker system prune -f

  # ðŸ“Š Analyse des performances
  performance-analysis:
    name: ðŸ“Š Analyse des Performances
    runs-on: ubuntu-latest
    needs: performance-tests
    if: always()
    timeout-minutes: 15
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pandas matplotlib

      - name: ðŸ“‹ Download performance artifacts
        uses: actions/download-artifact@v4
        with:
          path: performance-artifacts/

      - name: ðŸ“Š Generate performance report
        run: |
          echo "## ðŸš€ Rapport Tests de Performance Arkalia-LUNA" > performance-report.md
          echo "### ðŸ“… Date: $(date)" >> performance-report.md
          echo "### ðŸ”— Commit: ${{ github.sha }}" >> performance-report.md
          echo "### ðŸŒ¿ Branche: ${{ github.ref }}" >> performance-report.md
          echo "### ðŸƒâ€â™‚ï¸ Event: ${{ github.event_name }}" >> performance-report.md
          echo "" >> performance-report.md
          echo "### âœ… Statut des Tests:" >> performance-report.md
          echo "- ZeroIA: ${{ needs.performance-tests.result }}" >> performance-report.md
          echo "- API: ${{ needs.performance-tests.result }}" >> performance-report.md
          echo "- IntÃ©gration: ${{ needs.performance-tests.result }}" >> performance-report.md
          echo "" >> performance-report.md
          echo "### ðŸ“Š MÃ©triques CollectÃ©es:" >> performance-report.md

          # Analyse des rÃ©sultats
          if [ -d "performance-artifacts" ]; then
            echo "ðŸ“ Artifacts disponibles:" >> performance-report.md
            find performance-artifacts/ -type f -name "*.md" -exec echo "- {}" \; >> performance-report.md
            find performance-artifacts/ -type f -name "*.html" -exec echo "- {}" \; >> performance-report.md
          else
            echo "âš ï¸ Aucun artifact trouvÃ©" >> performance-report.md
          fi

          echo "" >> performance-report.md
          echo "### ðŸŽ¯ Seuils de Performance:" >> performance-report.md
          echo "- Temps de rÃ©ponse API: < 500ms" >> performance-report.md
          echo "- DÃ©cision ZeroIA: < 2s" >> performance-report.md
          echo "- Circuit breaker: < 10ms" >> performance-report.md
          echo "- Charge concurrente: 10 utilisateurs" >> performance-report.md

      - name: ðŸ“Š Run performance benchmark script
        run: |
          echo "ðŸ“Š ExÃ©cution du script de benchmark..."
          if [ -f "scripts/ark-performance-benchmark.py" ]; then
            python scripts/ark-performance-benchmark.py --report-only --output-format=markdown >> performance-report.md
          else
            echo "âš ï¸ Script de benchmark non trouvÃ©" >> performance-report.md
          fi

      - name: ðŸ“‹ Upload performance analysis
        uses: actions/upload-artifact@v4
        with:
          name: performance-analysis
          path: performance-report.md
          retention-days: 90

      - name: ðŸš¨ Alert on performance regression
        if: failure()
        run: |
          echo "âš ï¸ RÃ©gression de performance dÃ©tectÃ©e!"
          echo "ðŸ”— Voir les dÃ©tails: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          # Ici vous pourriez ajouter des alertes Slack/email
          # curl -X POST -H 'Content-type: application/json' --data '{"text":"âš ï¸ RÃ©gression de performance dÃ©tectÃ©e!"}' ${{ secrets.SLACK_WEBHOOK }}

  # ðŸ”„ Tests de performance de rÃ©gression
  regression-tests:
    name: ðŸ”„ Tests de RÃ©gression Performance
    runs-on: ubuntu-latest
    needs: performance-analysis
    if: github.event_name == 'schedule'
    timeout-minutes: 20
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ðŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pytest pytest-benchmark

      - name: ðŸ”„ Run regression tests
        run: |
          echo "ðŸ”„ Tests de rÃ©gression de performance..."

          # Tests de rÃ©gression basiques
          pytest tests/performance/ -v --benchmark-compare --benchmark-compare-fail=mean:10% || echo "âš ï¸ Tests de rÃ©gression terminÃ©s avec avertissements"

      - name: ðŸ“Š Generate regression report
        run: |
          echo "## ðŸ”„ Rapport Tests de RÃ©gression Performance" > regression-report.md
          echo "### ðŸ“… Date: $(date)" >> regression-report.md
          echo "### ðŸ”— Commit: ${{ github.sha }}" >> regression-report.md
          echo "" >> regression-report.md
          echo "### ðŸ“Š Comparaison avec baseline:" >> regression-report.md
          echo "- Seuil de tolÃ©rance: 10%" >> regression-report.md
          echo "- MÃ©triques comparÃ©es: temps de rÃ©ponse, dÃ©bit" >> regression-report.md

      - name: ðŸ“‹ Upload regression report
        uses: actions/upload-artifact@v4
        with:
          name: regression-report
          path: regression-report.md
          retention-days: 90
