---
name: 🚀 Tests de Performance

on:
  push:
    branches: [ main, develop, dev-migration, refonte-stable ]
  pull_request:
    branches: [ main, develop, dev-migration, refonte-stable ]
  schedule:
    # Tests de performance quotidiens à 2h du matin
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: "3.10"
  PERFORMANCE_TIMEOUT: 1800  # 30 minutes

# Permissions pour éviter les erreurs de sécurité
permissions:
  contents: read
  actions: read

jobs:
  # 🚀 Tests de performance complets
  performance-tests:
    name: 📊 Tests de Performance Complets
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      matrix:
        python-version: ["3.10"]
        test-suite: ["zeroia", "api", "integration"]
      fail-fast: false
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-benchmark pytest-timeout
          pip install aiohttp requests locust

      - name: 🧹 Clean performance artifacts
        run: |
          find . -name "._*" -delete
          find . -name ".DS_Store" -delete
          find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
          rm -rf .benchmarks/ performance-results/

      - name: 🐳 Setup Docker for performance tests
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            image=moby/buildkit:v0.12.0

      - name: 🐳 Start services for performance testing
        run: |
          echo "🚀 Démarrage des services pour tests de performance..."
          echo "🔨 Construction des images Docker..."
          docker compose build --no-cache
          docker compose up -d --remove-orphans
          sleep 60

      - name: 🏥 Health check before performance tests
        run: |
          echo "🏥 Vérification santé avant tests de performance..."
          for service in "8000/health" "8000/zeroia/health" "8000/reflexia/health"; do
            echo "🔍 Vérification $service..."
            for i in {1..10}; do
              if curl -f -s "http://localhost:$service" > /dev/null; then
                echo "✅ $service disponible"
                break
              else
                echo "⏳ Tentative $i/10 - $service non disponible"
                sleep 10
              fi
            done
          done

      - name: 🧪 Run Performance Tests - ${{ matrix.test-suite }}
        run: |
          echo "🧪 Exécution des tests de performance - ${{ matrix.test-suite }}..."
          case "${{ matrix.test-suite }}" in
            "zeroia")
              echo "📊 Tests de performance ZeroIA..."
              pytest tests/performance/zeroia/test_zeroia_performance.py::test_zeroia_decision_time_under_2s -v --benchmark-only
              pytest tests/performance/zeroia/test_zeroia_performance.py::test_circuit_breaker_latency_under_10ms -v --benchmark-only
              pytest tests/performance/zeroia/test_zeroia_performance.py::test_performance_regression_detection -v --benchmark-only
              ;;
            "api")
              echo "📊 Tests de performance API..."
              pytest tests/performance/api/ -v --benchmark-only --timeout=300 || echo "⚠️ Tests API terminés avec avertissements"
              ;;
            "integration")
              echo "📊 Tests de performance intégration..."
              pytest tests/performance/integration/ -v --benchmark-only --timeout=600 || echo "⚠️ Tests intégration terminés avec avertissements"
              ;;
          esac

      - name: 📊 Generate performance metrics
        run: |
          echo "📊 Génération des métriques de performance..."
          {
            echo "🔍 Métriques système:";
            echo "- CPU: $(top -bn1 | grep 'Cpu(s)' | awk '{print \$2}')";
            echo "- Mémoire: $(free -h | grep 'Mem:' | awk '{print \$7}') libres";
            echo "- Disque: $(df -h / | awk 'NR==2 {print \$4}') libres";
            echo "";
            echo "🐳 Métriques Docker:";
            docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}";
          } > performance-metrics-${{ matrix.test-suite }}.md

      - name: 📊 Run load tests with Locust
        run: |
          echo "📊 Tests de charge avec Locust..."
          if [ ! -f "locustfile.py" ]; then
            {
              echo 'from locust import HttpUser, task, between';
              echo '';
              echo 'class ArkaliaUser(HttpUser):';
              echo '    wait_time = between(1, 3)';
              echo '';
              echo '    @task(3)';
              echo '    def health_check(self):';
              echo '        self.client.get("/health")';
              echo '';
              echo '    @task(2)';
              echo '    def zeroia_decision(self):';
              echo '        self.client.get("/zeroia/decision")';
              echo '';
              echo '    @task(1)';
              echo '    def reflexia_health(self):';
              echo '        self.client.get("/reflexia/health")';
            } > locustfile.py
          fi
          locust -f locustfile.py --headless --users 10 --spawn-rate 2 --run-time 60s --html=load-test-report-${{ matrix.test-suite }}.html || echo "⚠️ Tests de charge terminés avec avertissements"

      - name: 📋 Upload performance artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results-${{ matrix.test-suite }}
          path: |
            .benchmarks/
            performance-metrics-${{ matrix.test-suite }}.md
            load-test-report-${{ matrix.test-suite }}.html
            performance-results/
          retention-days: 30

      - name: 🐳 Stop services
        if: always()
        run: |
          echo "🛑 Arrêt des services..."
          docker compose down --remove-orphans
          docker system prune -f

  # 📊 Analyse des performances
  performance-analysis:
    name: 📊 Analyse des Performances
    runs-on: ubuntu-latest
    needs: performance-tests
    if: always()
    timeout-minutes: 15
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pandas matplotlib

      - name: 📋 Download performance artifacts
        uses: actions/download-artifact@v4
        with:
          path: performance-artifacts/

      - name: 📊 Generate performance report
        run: |
          {
            echo "## 🚀 Rapport Tests de Performance Arkalia-LUNA";
            echo "### 📅 Date: $(date)";
            echo "### 🔗 Commit: ${{ github.sha }}";
            echo "### 🌿 Branche: ${{ github.ref }}";
            echo "### 🏃‍♂️ Event: ${{ github.event_name }}";
            echo "";
            echo "### ✅ Statut des Tests:";
            echo "- ZeroIA: ${{ needs.performance-tests.result }}";
            echo "- API: ${{ needs.performance-tests.result }}";
            echo "- Intégration: ${{ needs.performance-tests.result }}";
            echo "";
            echo "### 📊 Métriques Collectées:";
            if [ -d "performance-artifacts" ]; then
              echo "📁 Artifacts disponibles:";
              find performance-artifacts/ -type f -name "*.md" -exec echo "- {}" \;;
              find performance-artifacts/ -type f -name "*.html" -exec echo "- {}" \;;
            else
              echo "⚠️ Aucun artifact trouvé";
            fi
            echo "";
            echo "### 🎯 Seuils de Performance:";
            echo "- Temps de réponse API: < 500ms";
            echo "- Décision ZeroIA: < 2s";
            echo "- Circuit breaker: < 10ms";
            echo "- Charge concurrente: 10 utilisateurs";
          } > performance-report.md

      - name: 📊 Run performance benchmark script
        run: |
          echo "📊 Exécution du script de benchmark..."
          if [ -f "scripts/ark-performance-benchmark.py" ]; then
            python scripts/ark-performance-benchmark.py --report-only >> performance-report.md
          else
            echo "⚠️ Script de benchmark non trouvé" >> performance-report.md
          fi

      - name: 📋 Upload performance analysis
        uses: actions/upload-artifact@v4
        with:
          name: performance-analysis
          path: performance-report.md
          retention-days: 90

      - name: 🚨 Alert on performance regression
        if: failure()
        run: |
          echo "⚠️ Régression de performance détectée!"
          echo "🔗 Voir les détails: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          # Ici vous pourriez ajouter des alertes Slack/email
          # curl -X POST -H 'Content-type: application/json' --data '{"text":"⚠️ Régression de performance détectée!"}' ${{ secrets.SLACK_WEBHOOK }}

  # 🔄 Tests de performance de régression
  regression-tests:
    name: 🔄 Tests de Régression Performance
    runs-on: ubuntu-latest
    needs: performance-analysis
    if: github.event_name == 'schedule'
    timeout-minutes: 20
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pytest pytest-benchmark

      - name: 🔄 Run regression tests
        run: |
          echo "🔄 Tests de régression de performance..."
          pytest tests/performance/ -v --benchmark-compare --benchmark-compare-fail=mean:10% || echo "⚠️ Tests de régression terminés avec avertissements"

      - name: 📊 Generate regression report
        run: |
          {
            echo "## 🔄 Rapport Tests de Régression Performance";
            echo "### 📅 Date: $(date)";
            echo "### 🔗 Commit: ${{ github.sha }}";
            echo "";
            echo "### 📊 Comparaison avec baseline:";
            echo "- Seuil de tolérance: 10%";
            echo "- Métriques comparées: temps de réponse, débit";
          } > regression-report.md

      - name: 📋 Upload regression report
        uses: actions/upload-artifact@v4
        with:
          name: regression-report
          path: regression-report.md
          retention-days: 90
