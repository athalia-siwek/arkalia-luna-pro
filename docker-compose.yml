# üöÄ Arkalia Luna Pro ‚Äî Docker Compose Optimis√© v3.0
# Configuration haute performance avec s√©curit√© renforc√©e

x-arkalia-defaults: &arkalia-defaults
  build:
    context: .
  volumes:
    - ./logs:/app/logs
    - ./state:/app/state:rw
    - ./config:/app/config:ro
  working_dir: /app
  environment:
    - PYTHONUNBUFFERED=1
    - PYTHONDONTWRITEBYTECODE=1
  restart: unless-stopped
  networks:
    - arkalia_network
  security_opt:
    - no-new-privileges:true
  cap_drop:
    - ALL
  read_only: false # Chang√© pour permettre l'√©criture dans /app/logs

services:

  # üöÄ Helloria ‚Äî API centrale (FastAPI) Optimis√©e
  arkalia-api:
    <<: *arkalia-defaults
    container_name: arkalia-api
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${PORT_API:-8000}:8000"
    command: python run_arkalia_api.py
    environment:
      - ARKALIA_ENV=development
      - ARKALIA_LOG_LEVEL=INFO
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # ü§ñ AssistantIA ‚Äî Interface IA conversationnelle v2.8.0
  assistantia:
    <<: *arkalia-defaults
    container_name: assistantia
    build:
      context: .
      dockerfile: Dockerfile.assistantia
    image: arkalia-luna-assistantia:production
    ports:
      - "${PORT_ASSISTANTIA:-8001}:8001"
    command: >
      uvicorn modules.assistantia.core:app --host 0.0.0.0 --port 8001
        --workers 1 --access-log --log-level info
    environment:
      - ASSISTANTIA_ENV=production
      - ASSISTANTIA_LOG_LEVEL=INFO
      - OLLAMA_HOST=host.docker.internal
      - OLLAMA_PORT=11434
    depends_on:
      arkalia-api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8001/api/v1/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs
      - ./state:/app/state
      - ./modules/assistantia/logs:/app/modules/assistantia/logs
    networks:
      - arkalia_network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # üîÅ ReflexIA ‚Äî Observateur cognitif r√©flexif Optimis√©
  reflexia:
    <<: *arkalia-defaults
    container_name: reflexia
    build:
      context: .
      dockerfile: Dockerfile.reflexia
    ports:
      - "${PORT_REFLEXIA:-8002}:8002"
    command: python run_reflexia_api.py
    environment:
      - REFLEXIA_ENV=development
      - REFLEXIA_MONITORING_ENABLED=true
    healthcheck:
      test: [ "CMD", "python", "-c", "from modules.reflexia.core import launch_reflexia_check; launch_reflexia_check(); print('OK')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.8'
        reservations:
          memory: 256M
          cpus: '0.4'

  # ü§ñ ZeroIA ‚Äî D√©cisionneur autonome Enhanced v2.6.0 Optimis√©
  zeroia:
    <<: *arkalia-defaults
    container_name: zeroia
    build:
      context: .
      dockerfile: Dockerfile.zeroia
    image: arkalia-luna-zeroia:optimized
    command: python scripts/demo_orchestrator_enhanced.py --mode daemon
    environment:
      - ZEROIA_ENV=development
      - ZEROIA_HOLD_LOOP=false
      - ZEROIA_ENHANCED_MODE=true
      - ZEROIA_LOG_LEVEL=INFO
      - ZEROIA_INIT_TIMEOUT=120
      - ZEROIA_MAX_RETRIES=5
      - ZEROIA_STARTUP_DELAY=15
      - ZEROIA_GRACEFUL_SHUTDOWN=true
    depends_on:
      reflexia:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "true" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    volumes:
      - ./modules/zeroia/state:/app/modules/zeroia/state
      - ./logs:/app/logs
      - ./state:/app/state
    networks:
      - arkalia_network

  # üß† Sandozia ‚Äî Intelligence Crois√©e Enterprise v2.6.0 Optimis√©e
  sandozia:
    <<: *arkalia-defaults
    container_name: sandozia
    build:
      context: .
      dockerfile: Dockerfile.sandozia
    image: arkalia-luna-sandozia:optimized
    command: python scripts/demo_sandozia.py --daemon
    environment:
      - SANDOZIA_ENV=development
      - SANDOZIA_MONITORING_ENABLED=true
      - SANDOZIA_LOG_LEVEL=INFO
      - SANDOZIA_ENHANCED_MODE=true
    depends_on:
      zeroia:
        condition: service_healthy
      reflexia:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "python", "-c", "from modules.sandozia.core.sandozia_core import SandoziaCore; print('OK')" ]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.5'
        reservations:
          memory: 512M
          cpus: '0.8'

  # üß† Cognitive Reactor ‚Äî Intelligence Avanc√©e v2.7.0 Production Ready
  cognitive-reactor:
    <<: *arkalia-defaults
    container_name: cognitive-reactor
    build:
      context: .
      dockerfile: Dockerfile.cognitive-reactor
    image: arkalia-luna-cognitive:production
    ports:
      - "${PORT_COGNITIVE:-8003}:8003"
    command: --mode production --daemon
    environment:
      - COGNITIVE_REACTOR_ENV=production
      - COGNITIVE_REACTOR_ENABLED=true
      - CHRONALIA_ENABLED=true
      - COGNITIVE_LOG_LEVEL=INFO
      - COGNITIVE_MAX_REACTIONS=100
      - COGNITIVE_REACTION_INTERVAL=30
    depends_on:
      sandozia:
        condition: service_healthy
      zeroia:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "python", "-c", "from modules.cognitive_reactor.core import CognitiveReactor; print('CognitiveReactor OK')" ]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 45s
    restart: unless-stopped
    volumes:
      - ./modules/cognitive_reactor/state:/app/modules/cognitive_reactor/state
      - ./logs:/app/logs
      - ./state:/app/state
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # üöÄ Generative AI ‚Äî Intelligence G√©n√©rative Avanc√©e v2.8.0
  # generative-ai:
  #   <<: *arkalia-defaults
  #   container_name: generative-ai
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.generative-ai
  #   image: arkalia-luna-generative:production
  #   ports:
  #     - "${PORT_GENERATIVE_AI:-8003}:8001"
  #   command: --mode production --daemon --max-generations 100 --interval 120
  #   environment:
  #     - GENERATIVE_AI_ENV=production
  #     - GENERATIVE_AI_ENABLED=true
  #     - GENERATIVE_AI_MAX_GENERATIONS=100
  #     - GENERATIVE_AI_INTERVAL=120
  #     - GENERATIVE_LOG_LEVEL=INFO
  #   depends_on:
  #     cognitive-reactor:
  #       condition: service_healthy
  #     sandozia:
  #       condition: service_healthy
  #   healthcheck:
  #     test: [ "CMD", "python", "-c", "from modules.generative_ai.core import GenerativeAI; print('GenerativeAI OK')" ]
  #     interval: 90s
  #     timeout: 20s
  #     retries: 3
  #     start_period: 60s
  #   restart: unless-stopped
  #   volumes:
  #     - ./modules/generative_ai/state:/app/modules/generative_ai/state
  #     - ./modules/generative_ai/generated:/app/modules/generative_ai/generated
  #     - ./logs:/app/logs
  #     - ./state:/app/state
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 768M
  #         cpus: '1.2'
  #       reservations:
  #         memory: 384M
  #         cpus: '0.6'

networks:
  arkalia_network:
    driver: bridge
    name: arkalia_network
